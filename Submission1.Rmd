---
title: "Predicting Listening Time"
author: "Eric Zarycki"
date: "2025-04-10"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r}
# Visualization Packages
library(ggplot2)
library(ggthemes)
library(RColorBrewer)

# Predictive Packages
library(tidymodels)
library(textrecipes)
library(glmnet)
library(imputeTS)

# Other
library(dplyr)
library(sqldf)

```


```{r}
test <- readr::read_csv("Data/test.csv")
train <- readr::read_csv("Data/train.csv")
```


```{r}
head(train)
```

```{r}
summary(train)
```
Exploratory Data Analysis - Categorical Variables

Which Podcasts appear the most in the Training Dataset the most?
```{r}

mostpoppods <- sqldf("
  
      SELECT Podcast_Name,
      COUNT(*) as n
      FROM train
      GROUP BY Podcast_Name
      ORDER BY 2 DESC
      LIMIT 10
      
      ")

ggplot(mostpoppods, aes(x = reorder(Podcast_Name, -n), y = n, fill = Podcast_Name)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = n), vjust = 2, size = 3.5) +
  scale_fill_brewer(palette = "Set3") +  # Other good ones: "Paired", "Dark2", "Pastel1"
  labs(title = "Top 10 Podcasts in Training Dataset by Frequency",
       x = "Podcast Name", y = "Count") +
  theme_minimal(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none")

```
What genre appears the most in the training dataset the most frequently?

```{r}

popgenre <- sqldf("
      SELECT Genre,
      COUNT(*) as n
      FROM train
      GROUP BY Genre
      ORDER BY 2 DESC
      ")

ggplot(popgenre, aes(x = reorder(Genre, -n), y = n, fill = Genre)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = n), vjust = 2, size = 3.5) +
  scale_fill_brewer(palette = "Set3") +  # Other good ones: "Paired", "Dark2", "Pastel1"
  labs(title = "Most Frequent Genres in Training Dataset",
       x = "Genre Name", y = "Count") +
  theme_minimal(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none")



```
Distribution of Episode Title by Frequnecy (Top 10)

```{r}
popepisode <- sqldf("
      SELECT Episode_Title,
      COUNT(*) as n
      FROM train
      GROUP BY Episode_Title
      ORDER BY n DESC
      LIMIT 10
      ")

ggplot(popepisode, aes(x = reorder(Episode_Title, -n), y = n, fill = Episode_Title)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = n), vjust = 2, size = 3.5) +
  scale_fill_brewer(palette = "Set3") +  # Other good ones: "Paired", "Dark2", "Pastel1"
  labs(title = "Top 10 Episodes in Training Dataset by Frequency",
       x = "Episode Title", y = "Count") +
  theme_minimal(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none")
```




Day and Time
```{r}
popday <- sqldf("
      SELECT Publication_Day,
      Publication_Time,
      COUNT(*) as n
      FROM train
      GROUP BY Publication_Day,
      Publication_Time
      ORDER BY n DESC
      ")

popday$Publication_Day <- factor(popday$Publication_Day, 
                              levels = c("Sunday", "Monday", "Tuesday", "Wednesday", 
                                         "Thursday", "Friday", "Saturday"))

ggplot(popday, aes(x = Publication_Day, y = n, fill = Publication_Time)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = n), 
            position = position_stack(vjust = 0.5), # Centers label within each segment
            size = 3) +
  labs(title = "Distribution by Day and Time of Podcast",
       x = "Day", y = "Count") +
  scale_fill_brewer(palette = "Set3") +  # You can change color palette here
  theme_minimal(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
Distribution of Sentiment 

```{r}
sent <- sqldf("
      SELECT Episode_Sentiment,
      COUNT(*) as n
      FROM train
      GROUP BY Episode_Sentiment
      ")

ggplot(sent, aes(x = Episode_Sentiment, y = n, fill = Episode_Sentiment)) +
  geom_bar(stat = "identity") +
    geom_text(aes(label = n), vjust = 2, size = 3.5) +
  labs(title = "Sentiment by Frequency",
       x = "Sentiment", y = "Count") +
  scale_fill_manual(values = c("Positive" = "lightgreen", "Negative" = "red", "Neutral" = "gray")) +  # You can choose a different palette here
  theme_minimal(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Numerical Variable Analysis

Episode Length Minutes vs. Listening Time Minutes

```{r}

epwatched <- sqldf("
      SELECT Episode_Length_minutes,
      Listening_Time_minutes
      FROM train
      WHERE Episode_Length_minutes IS NOT NULL
      ")

ggplot(epwatched, aes(x = Episode_Length_minutes, y = Listening_Time_minutes)) +
  geom_hex() +
  scale_fill_viridis_c() +  # Color scale for density
  labs(title = "Hexbin Plot: Episode Length vs Listening Time",
       x = "Episode Length (Minutes)", y = "Listening Time (Minutes)") +
  theme_minimal(base_size = 12)

```

## Building the Model

```{r}
set.seed(123)

# Sample and split
train_sample <- train %>% slice_sample(n=100000)

train_split <- train_sample %>% initial_split(strata = Listening_Time_minutes)

ltm_train <- training(train_split)
ltm_test <- testing(train_split)

set.seed(456)
ltm_folds <- vfold_cv(ltm_train, strata = Listening_Time_minutes)
ltm_folds

```

## Preprocessing

```{r}
ltm_recipe <- ltm_train %>% recipe(Listening_Time_minutes ~.) %>% 
  step_rm(id, Podcast_Name, Episode_Title, Number_of_Ads, Publication_Day, Publication_Time) %>% 
  step_naomit(all_predictors()) %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_dummy(all_nominal_predictors())
  
```

## Specifications

```{r}

linear_spec <-
  linear_reg(penalty = 0.256, mixture = 0.781) %>% set_mode("regression") %>%
  set_engine("glmnet")
  

```

## Workflow

```{r}
linear_wf <- workflow(ltm_recipe,linear_spec)
```

## Grid
```{r}
grid_vals <- grid_random(
  penalty(),
  mixture(),
  size = 20  # random 20 combinations
)

tune_results <- tune_grid(
  linear_wf,
  resamples = ltm_folds,  # your cross-validation folds
  grid = grid_vals,
  control = control_grid(save_pred = TRUE)
)

autoplot(tune_results)
```


## Evaluate models

```{r}
#doParallel::registerDoParallel()
contrl_preds <- control_resamples(save_pred = TRUE)

linear_rs <- fit_resamples(linear_wf,
                           resamples = ltm_folds,
                           control=contrl_preds)

```

## Results
```{r}
collect_metrics(linear_rs)
```

## Final Fit
```{r}
final_fitted <- last_fit(linear_wf,train_split)
```

## Fitted Worokflow for prediction
```{r}
final_wf <- extract_workflow(final_fitted)
```


## Submission
```{r}
final_prediction <- predict(final_wf, new_data = test)

submission <- test %>% select(id) %>% bind_cols(round(final_prediction,3))

colnames(submission) <- c("id", "Listening_Time_minutes")

submission$Listening_Time_minutes <- submission$Listening_Time_minutes %>% 
  na_interpolation("linear")

```

##Result
```{r}
submission %>% 
  write_csv("submission2.csv")
```






